{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0cf540e2",
   "metadata": {},
   "source": [
    "### Q3: perform Bayesian Multivariate Classification\n",
    "\n",
    "- For a data set for which modeling multiple binary outcomes might be interesting (perhaps from kaggle.com?)\n",
    "- Use `pm.Normal('betas', mu=0, sigma=1, shape=(p,m))` rather than a `pm.MvNormal` alternative\n",
    "- Use `y = pm.Bernoulli('y', p=pm.math.invprobit(X@betas), observed=x)` for `(n,m)` shaped `y` and `(n,p)` shaped `X`\n",
    "- Use latent `z = pm.MvNormal('z', mu=X@betas, chol=L)` as discussed in the \"Generalized Linear Models (GLM)\" section of the previous weeks lecture notes\n",
    "\n",
    "> This provides normally distributed latent variables connected to the observed binary outcomes on which a latent covariance dependency structure may be modelled and estimated on the basis of imputing the unobserved latent variables based on their connection with the observed binary outcome variables.\n",
    "\n",
    "- Downsample your dataset to tentatively explore the effect of different values of `n`,`m`,`p` and \n",
    "    - report on your findings and based on that \n",
    "    - choose a \"reasonably small\" sized data set to perform an actual analysis\n",
    "- Provide inference with Bayesian posterior analysis and report MCMC diagnostics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1652e36",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [betas, packed_L, z]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      <progress value='8000' class='' max='8000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [8000/8000 19:36&lt;00:00 Sampling 4 chains, 692 divergences]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling 4 chains for 1_000 tune and 1_000 draw iterations (4_000 + 4_000 draws total) took 1178 seconds.\n",
      "The rhat statistic is larger than 1.01 for some parameters. This indicates problems during sampling. See https://arxiv.org/abs/1903.08008 for details\n",
      "The effective sample size per chain is smaller than 100 for some parameters.  A higher number is needed for reliable rhat and ess computation. See https://arxiv.org/abs/1903.08008 for details\n",
      "There were 692 divergences after tuning. Increase `target_accept` or reparameterize.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "n=100, p=2, m=2 -> max R-hat(betas): 1.110\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [betas, packed_L, z]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      <progress value='8000' class='' max='8000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [8000/8000 18:34&lt;00:00 Sampling 4 chains, 1,677 divergences]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling 4 chains for 1_000 tune and 1_000 draw iterations (4_000 + 4_000 draws total) took 1116 seconds.\n",
      "The rhat statistic is larger than 1.01 for some parameters. This indicates problems during sampling. See https://arxiv.org/abs/1903.08008 for details\n",
      "The effective sample size per chain is smaller than 100 for some parameters.  A higher number is needed for reliable rhat and ess computation. See https://arxiv.org/abs/1903.08008 for details\n",
      "There were 1677 divergences after tuning. Increase `target_accept` or reparameterize.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "n=100, p=4, m=2 -> max R-hat(betas): 1.100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [betas, packed_L, z]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      <progress value='8000' class='' max='8000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [8000/8000 18:48&lt;00:00 Sampling 4 chains, 1,123 divergences]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling 4 chains for 1_000 tune and 1_000 draw iterations (4_000 + 4_000 draws total) took 1129 seconds.\n",
      "The rhat statistic is larger than 1.01 for some parameters. This indicates problems during sampling. See https://arxiv.org/abs/1903.08008 for details\n",
      "The effective sample size per chain is smaller than 100 for some parameters.  A higher number is needed for reliable rhat and ess computation. See https://arxiv.org/abs/1903.08008 for details\n",
      "There were 1123 divergences after tuning. Increase `target_accept` or reparameterize.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "n=200, p=2, m=2 -> max R-hat(betas): 1.270\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [betas, packed_L, z]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      <progress value='1435' class='' max='8000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      17.94% [1435/8000 04:13&lt;19:20 Sampling 4 chains, 0 divergences]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pymc as pm\n",
    "import arviz as az\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# 1) Load the Pima Indians Diabetes dataset (Kaggle version or UCI version)\n",
    "#    Make sure \"Outcome\" is 0/1 indicating diabetes or not.\n",
    "df = pd.read_csv(\"diabetes.csv\")  # Adjust to your path\n",
    "\n",
    "# 2) Introduce a SECOND binary outcome\n",
    "#    Example: \"HighBMI\" = 1 if BMI >= 30, else 0\n",
    "df[\"HighBMI\"] = (df[\"BMI\"] >= 30).astype(int)\n",
    "\n",
    "# 3) Define your outcome columns (m = 2)\n",
    "outcome_cols = [\"Outcome\", \"HighBMI\"]\n",
    "m = len(outcome_cols)\n",
    "\n",
    "# 4) Define potential predictors (you can reduce or rearrange as needed)\n",
    "predictor_cols = [\n",
    "    \"Glucose\", \n",
    "    \"BloodPressure\", \n",
    "    \"Insulin\", \n",
    "    \"Age\"\n",
    "]\n",
    "p_all = len(predictor_cols)\n",
    "\n",
    "# 5) Choose different n-levels (downsample/truncate sizes)\n",
    "#    e.g., small, medium, and full\n",
    "n_values = [100, 200, 300]\n",
    "\n",
    "# Optionally vary p as well (e.g., fewer or all predictors)\n",
    "p_values = [2, p_all]\n",
    "\n",
    "# We'll store basic diagnostics in a list\n",
    "results = []\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 6) Loop over the dataset sizes and number of predictors\n",
    "# ------------------------------------------------------------\n",
    "for n_ in n_values:\n",
    "    # Downsample/truncate the dataset\n",
    "    # Here we randomly sample n_ rows (you could also do df.head(n_))\n",
    "    df_subset = df.sample(n=n_, random_state=42)\n",
    "\n",
    "    for p_ in p_values:\n",
    "        # Pick the first p_ columns from predictor_cols\n",
    "        current_predictors = predictor_cols[:p_]\n",
    "        \n",
    "        # Extract X (shape = (n_, p_)) and y (shape = (n_, m))\n",
    "        X_data = df_subset[current_predictors].values\n",
    "        y_data = df_subset[outcome_cols].values\n",
    "        \n",
    "        # (Optional) Standardize predictors for better MCMC sampling\n",
    "        X_data = StandardScaler().fit_transform(X_data)\n",
    "\n",
    "        # 7) Build the Bayesian Correlated Probit Model\n",
    "        with pm.Model() as multivariate_model:\n",
    "            # (a) Priors for regression coefficients (p_, m)\n",
    "            betas = pm.Normal(\"betas\", mu=0, sigma=1, shape=(p_, m))\n",
    "            \n",
    "            # (b) LKJ Cholesky prior for correlation among latent dimensions\n",
    "            packed_L = pm.LKJCholeskyCov(\n",
    "                \"packed_L\",\n",
    "                n=m,\n",
    "                eta=2.0, \n",
    "                sd_dist=pm.Exponential.dist(1.0, shape=m),\n",
    "                compute_corr=False\n",
    "            )\n",
    "            L = pm.expand_packed_triangular(m, packed_L)\n",
    "            \n",
    "            # (c) Latent variable z: shape = (n_, m)\n",
    "            mu = pm.math.dot(X_data, betas)\n",
    "            z = pm.MvNormal(\"z\", mu=mu, chol=L, shape=(n_, m))\n",
    "            \n",
    "            # (d) Probit link => p = Î¦(z)\n",
    "            p = pm.math.invprobit(z)\n",
    "            \n",
    "            # (e) Bernoulli likelihood for multiple binary outcomes\n",
    "            y_obs = pm.Bernoulli(\"y_obs\", p=p, observed=y_data)\n",
    "\n",
    "            # (f) MCMC sampling\n",
    "            trace = pm.sample()\n",
    "\n",
    "        # 8) Basic diagnostics: check R-hat, etc.\n",
    "        summary_ = az.summary(trace, var_names=[\"betas\"])\n",
    "        max_rhat = summary_[\"r_hat\"].max()\n",
    "        \n",
    "        results.append({\n",
    "            \"n\": n_,\n",
    "            \"p\": p_,\n",
    "            \"m\": m,\n",
    "            \"max_rhat\": max_rhat\n",
    "        })\n",
    "        print(f\"\\nn={n_}, p={p_}, m={m} -> max R-hat(betas): {max_rhat:.3f}\")\n",
    "\n",
    "# 9) Optional: convert results to a DataFrame for easy comparison\n",
    "results_df = pd.DataFrame(results)\n",
    "print(\"\\nSummary of runs:\")\n",
    "print(results_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1fc4ba5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
